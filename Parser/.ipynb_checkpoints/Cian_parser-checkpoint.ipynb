{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # для запросов html страниц\n",
    "from bs4 import BeautifulSoup # для работы со структурой html страниц\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#С помощью селениума делаем клики на веб странцах\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#По ссылке получим текст html страницы\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "#Получим текст страницы с помощью селениума\n",
    "def get_html_data():\n",
    "    return browser.page_source\n",
    "#Возвращает даты создания объявлений\n",
    "def creation_date(time_sleep, url_ad):\n",
    "    browser.get(url_ad)\n",
    "    browser.find_element_by_xpath(\"//a[@class='a10a3f92e9--link--1t8n1 a10a3f92e9--link--2mJJk']\").click()\n",
    "    time.sleep(time_sleep)\n",
    "    soup_date = BeautifulSoup(get_html_data(), 'html')\n",
    "    pattern = re.compile(r'\\d+\\.\\d+\\.\\d{0,4}')\n",
    "    c = soup_date.find('div', 'a10a3f92e9--information--AyP9e').text\n",
    "    creation_date_ = pattern.findall(c)[0]\n",
    "    return creation_date_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ['https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=1&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room9=1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(url)):\n",
    "    url[i] = url[i].replace('&region', '&p=1&region')\n",
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&p=1&region=1&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room9=1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В целом нам нужны собрать данные, которые указаны ниже, в столбцах DataFrame-е\n",
    "df = pd.DataFrame(columns=['Ссылка', 'Город', 'Точный адрес', 'Метро', 'Заголовок объявления', 'Сегмент', 'Количество комнат',\n",
    "                           'Описание', 'Тип сделки', 'Цена предложения, руб.', 'Общая площадь, кв.м', 'Дата создания',\n",
    "                           'Количество просмотров'])\n",
    "\n",
    "# for cian creation_date\n",
    "browser = webdriver.Chrome()\n",
    "#browser.implicitly_wait(10)\n",
    "#browser.set_page_load_timeout(12)\n",
    "\n",
    "for url_ in tqdm_notebook(url):    \n",
    "    # Определим тип сделки по url\n",
    "    if 'sale' in url_:\n",
    "        deal_type = 'Продажа'\n",
    "    elif 'rent' in url_:\n",
    "        deal_type = 'Аренда'        \n",
    "    #Total_pages\n",
    "    connected = False\n",
    "    while connected == False:\n",
    "        try:\n",
    "            html_total_pages = get_html(url_)\n",
    "            connected = True\n",
    "        except:\n",
    "            pass\n",
    "    soup_total_pages = BeautifulSoup(html_total_pages, 'html')#\n",
    "    total_pages_str = soup_total_pages.find('div', '_93444fe79c--header--3pKNW').text\n",
    "    total_pages = int(int(''.join(re.findall('\\d+', total_pages_str)))/28)+1\n",
    "    if total_pages > 54:\n",
    "        total_pages = 54\n",
    "    print('Номер ссылки:', url.index(url_)+1, 'Количество страниц:', total_pages)\n",
    "    print('Размер df:', df.shape)\n",
    "    \n",
    "    # Get all ads on page\n",
    "    for page_num in range(1, total_pages+1):\n",
    "        print('page_num:', page_num)\n",
    "        page_link = url_.replace('p=1', 'p='+str(page_num))\n",
    "        connected = False\n",
    "        while connected == False:\n",
    "            try:\n",
    "                html_page = get_html(page_link)\n",
    "                connected = True\n",
    "            except:\n",
    "                print('page problem')\n",
    "                pass\n",
    "        soup_page = BeautifulSoup(html_page, 'html')\n",
    "        city = soup_page.find('div', '_93444fe79c--filters-item--2yZB0 _93444fe79c--filters-item--location--1YKT_').text\n",
    "        ads = soup_page.find('div', '_93444fe79c--wrapper--E9jWb').find_all('div', '_93444fe79c--card--_yguQ')\n",
    "        for ad in ads:\n",
    "            time_sleep = 2 # only for cian\n",
    "            d = {}\n",
    "            ad_link = ad.find('a', 'c6e8ba5398--header--1fV2A').get('href')\n",
    "            connected = False\n",
    "            while connected == False:\n",
    "                try:\n",
    "                    html_ad = get_html(ad_link)\n",
    "                    connected = True\n",
    "                except:\n",
    "                    print('ad_disconnect')\n",
    "                    pass\n",
    "            soup_ad = BeautifulSoup(html_ad, 'html')\n",
    "            d['Ссылка'] = ad_link\n",
    "            d['Город'] = city\n",
    "            try:\n",
    "                d['Точный адрес'] = soup_ad.find('address', 'a10a3f92e9--address--140Ec').text.replace('На карте', '')\n",
    "            except:\n",
    "                try:\n",
    "                    d['Точный адрес'] = soup_ad.find('div', 'a10a3f92e9--address--rAWUf').text\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                metro_list = soup_ad.find_all('li', 'a10a3f92e9--underground--kONgx')\n",
    "                metro = []\n",
    "                for m in metro_list:\n",
    "                    metro_name = m.find('a').text\n",
    "                    metro_dist = m.find('span').text.strip().replace('⋅  ', '')\n",
    "                    full_metro = metro_name+' '+metro_dist\n",
    "                    metro.append(full_metro)\n",
    "                metro = '; '.join(metro)\n",
    "                d['Метро'] = metro\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                d['Заголовок объявления'] = soup_ad.find('h1', 'a10a3f92e9--title--2Widg').text\n",
    "            except:\n",
    "                pass\n",
    "            d['Сегмент'] = 'Квартиры'\n",
    "            d['Количество комнат'] = None\n",
    "            try:\n",
    "                d['Описание'] = soup_ad.find('p', 'a10a3f92e9--description-text--3Sal4').text.replace('\\n', ' ')\n",
    "            except:\n",
    "                pass\n",
    "            d['Тип сделки'] = deal_type\n",
    "            try:\n",
    "                price_str = soup_ad.find('div', 'a10a3f92e9--price--1HD9F').find('span', {'itemprop': 'price'}).text\n",
    "                d['Цена предложения, руб.'] = float(''.join(re.findall('\\d+', price_str)))\n",
    "            except:\n",
    "                pass\n",
    "            d['Общая площадь, кв.м'] = None\n",
    "            \n",
    "            check_date = False\n",
    "            while check_date == False:\n",
    "                try:\n",
    "                    creation_date_ = creation_date(time_sleep, ad_link)\n",
    "                    d['Дата создания'] = creation_date_\n",
    "                    check_date = True\n",
    "                except:\n",
    "                    print('time sleep', time_sleep)\n",
    "                    time_sleep += 1\n",
    "            try:\n",
    "                views_count_str = soup_ad.find('a', 'a10a3f92e9--link--1t8n1 a10a3f92e9--link--2mJJk').text\n",
    "                d['Количество просмотров'] = int(''.join(re.findall('\\d', views_count_str.split(', ')[0])))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # extra properties\n",
    "            prop_1, prop_2, prop_3 = None, None, None\n",
    "            try:\n",
    "                #Общая площадь, жилая площадь, кухня, ...\n",
    "                prop_1 = soup_ad.find('div', 'a10a3f92e9--description--3uuO6').find_all('div', 'a10a3f92e9--info--3XiXi')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if prop_1 != None:\n",
    "                    for prop in prop_1:\n",
    "                        value = prop.find_all('div')[0].text\n",
    "                        name = prop.find_all('div')[1].text\n",
    "                        d[name] = value\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                 #Тип жиля,..\n",
    "                prop_2 = soup_ad.find('ul', 'a10a3f92e9--list--2M4V-').find_all('li')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if prop_2 != None:\n",
    "                    for prop in prop_2:\n",
    "                        name = prop.find_all('span')[0].text\n",
    "                        value = prop.find_all('span')[1].text\n",
    "                        d[name] = value\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                #Тип дома, лифт, парковка                \n",
    "                prop_3 = soup_ad.find('div', 'a10a3f92e9--column--2oGBs').find_all('div', 'a10a3f92e9--item--2Ig2y')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if prop_3 != None:\n",
    "                    for prop in prop_3:\n",
    "                        name = prop.find_all('div')[0].text\n",
    "                        value = prop.find_all('div')[1].text\n",
    "                        d[name] = value\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            df = df.append(d, ignore_index=True)\n",
    "    df.to_csv('../../Данные/Жилая/Август2020/Cian_aparts_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
